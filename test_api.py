"""
Script de prueba para la API de Validaci√≥n de Textos v2.0
Integra m√∫ltiples m√©todos de an√°lisis: Transformers (BERT), TextBlob y VADER
"""

import requests
import json
import time

# Configuraci√≥n
API_BASE_URL = "http://localhost:8000"

def test_health_check():
    """Prueba el endpoint de salud"""
    print("üîç Probando endpoint de salud...")
    try:
        response = requests.get(f"{API_BASE_URL}/health")
        if response.status_code == 200:
            print("‚úÖ API est√° funcionando correctamente")
            print(f"   GPU disponible: {response.json().get('gpu_available', False)}")
            print(f"   M√©todos disponibles: {response.json().get('available_methods', [])}")
            print(f"   M√©todo por defecto: {response.json().get('default_method', 'N/A')}")
        else:
            print(f"‚ùå Error en health check: {response.status_code}")
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")

def test_methods_info():
    """Prueba el endpoint de informaci√≥n de m√©todos"""
    print("\nüìö Probando informaci√≥n de m√©todos...")
    try:
        response = requests.get(f"{API_BASE_URL}/methods")
        if response.status_code == 200:
            data = response.json()
            print("‚úÖ Informaci√≥n de m√©todos obtenida:")
            for method, info in data["available_methods"].items():
                print(f"   üîπ {method}: {info['description']}")
                print(f"      Ventajas: {', '.join(info['advantages'])}")
                print(f"      Desventajas: {', '.join(info['disadvantages'])}")
        else:
            print(f"‚ùå Error obteniendo m√©todos: {response.status_code}")
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")

def test_method_comparison():
    """Prueba el endpoint de comparaci√≥n de m√©todos"""
    print("\n‚öñÔ∏è Probando comparaci√≥n de m√©todos...")
    try:
        response = requests.get(f"{API_BASE_URL}/compare")
        if response.status_code == 200:
            data = response.json()
            print("‚úÖ Comparaci√≥n de m√©todos obtenida:")
            print(f"   M√©todo recomendado: {data['recommended']}")
            for method, info in data['methods'].items():
                print(f"   üîπ {method}: {info['recommended_for']}")
        else:
            print(f"‚ùå Error obteniendo comparaci√≥n: {response.status_code}")
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")

def test_text_validation_with_method(text, description, method="transformers"):
    """Prueba la validaci√≥n de un texto espec√≠fico con un m√©todo determinado"""
    print(f"\nüìù Probando: {description}")
    print(f"   Texto: '{text}'")
    print(f"   M√©todo: {method}")
    
    try:
        start_time = time.time()
        response = requests.post(
            f"{API_BASE_URL}/validate",
            json={"text": text, "language": "es", "sentiment_method": method}
        )
        end_time = time.time()
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ Validaci√≥n exitosa ({end_time - start_time:.2f}s)")
            print(f"   Es ofensivo: {result['is_offensive']}")
            print(f"   Tiene groser√≠as: {result['has_profanity']}")
            print(f"   Score de emoci√≥n: {result['emotion_score']:.3f} ({result['emotion_label']})")
            print(f"   N√∫mero de groser√≠as: {result['profanity_count']}")
            print(f"   Confianza: {result['confidence']:.3f}")
            print(f"   M√©todo usado: {result['sentiment_method']}")
            print(f"   Tiempo de procesamiento: {result['processing_time']:.3f}s")
            print(f"   Texto corregido: '{result['corrected_text']}'")
            print("   Sugerencias:")
            for i, suggestion in enumerate(result['suggestions'], 1):
                print(f"     {i}. {suggestion}")
        else:
            print(f"‚ùå Error en validaci√≥n: {response.status_code}")
            print(f"   Detalle: {response.text}")
            
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")

def test_all_methods_with_same_text(text, description):
    """Prueba todos los m√©todos de an√°lisis con el mismo texto"""
    print(f"\nüß™ Probando todos los m√©todos con: '{description}'")
    
    methods = ["transformers", "textblob", "vader"]
    results = {}
    
    for method in methods:
        try:
            response = requests.post(
                f"{API_BASE_URL}/validate",
                json={"text": text, "language": "es", "sentiment_method": method}
            )
            
            if response.status_code == 200:
                result = response.json()
                results[method] = {
                    "score": result['emotion_score'],
                    "label": result['emotion_label'],
                    "confidence": result['confidence'],
                    "processing_time": result['processing_time']
                }
            else:
                results[method] = {"error": f"HTTP {response.status_code}"}
                
        except Exception as e:
            results[method] = {"error": str(e)}
    
    # Mostrar comparaci√≥n
    print("   üìä Comparaci√≥n de m√©todos:")
    for method, result in results.items():
        if "error" in result:
            print(f"     ‚ùå {method}: {result['error']}")
        else:
            print(f"     ‚úÖ {method}: Score={result['score']:.3f}, Label={result['label']}, Conf={result['confidence']:.3f}, Time={result['processing_time']:.3f}s")

def test_batch_validation():
    """Prueba la validaci√≥n en lote"""
    print("\nüì¶ Probando validaci√≥n en lote...")
    
    texts = [
        "Excelente trabajo equipo!",
        "Me siento frustrado con los resultados",
        "Este es un proyecto incre√≠ble",
        "No puedo creer lo mal que est√° esto"
    ]
    
    try:
        response = requests.post(
            f"{API_BASE_URL}/validate/batch",
            params={"method": "transformers"},
            json=texts
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ Procesados {result['total_texts']} textos con m√©todo {result['method']}")
            print(f"   Textos v√°lidos: {result['valid_texts']}")
            
            for i, text_result in enumerate(result['results']):
                if text_result['valid']:
                    status = "üü¢" if not text_result['is_offensive'] else "üî¥"
                    print(f"   {status} Texto {i+1}: Score={text_result['emotion_score']:.3f}, Groser√≠as={text_result['profanity_count']}")
                else:
                    print(f"   ‚ùå Texto {i+1}: {text_result['error']}")
        else:
            print(f"‚ùå Error en validaci√≥n por lotes: {response.status_code}")
            print(f"   Detalle: {response.text}")
            
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")

def run_all_tests():
    """Ejecuta todas las pruebas"""
    print("üöÄ Iniciando pruebas de la API de Validaci√≥n de Textos v2.0\n")
    
    # Prueba de salud
    test_health_check()
    
    # Informaci√≥n de m√©todos
    test_methods_info()
    
    # Comparaci√≥n de m√©todos
    test_method_comparison()
    
    # Casos de prueba con diferentes m√©todos
    test_cases = [
        {
            "text": "Hola, me encanta este proyecto! Es muy interesante y √∫til.",
            "description": "Texto positivo y apropiado"
        },
        {
            "text": "Este producto es una mierda, no funciona nada bien.",
            "description": "Texto con groser√≠a y emoci√≥n negativa"
        },
        {
            "text": "Estoy muy enojado con el servicio al cliente, son unos incompetentes.",
            "description": "Texto con emoci√≥n negativa pero sin groser√≠as"
        },
        {
            "text": "¬°Qu√© d√≠a tan maravilloso! El sol brilla y todo est√° perfecto.",
            "description": "Texto muy positivo"
        },
        {
            "text": "Este c√≥digo est√° mal hecho, el desarrollador es un gilipollas.",
            "description": "Texto con groser√≠a y cr√≠tica negativa"
        },
        {
            "text": "Necesito ayuda con mi proyecto, ¬øalguien puede ayudarme?",
            "description": "Texto neutral solicitando ayuda"
        }
    ]
    
    print(f"\nüß™ Ejecutando {len(test_cases)} casos de prueba con m√©todo por defecto...")
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n--- Prueba {i}/{len(test_cases)} ---")
        test_text_validation_with_method(test_case["text"], test_case["description"])
        time.sleep(1)  # Pausa entre pruebas
    
    # Prueba de comparaci√≥n de m√©todos
    print(f"\nüî¨ Probando comparaci√≥n de m√©todos...")
    test_all_methods_with_same_text(
        "Este producto es incre√≠ble, me encanta mucho!",
        "Texto positivo para comparar m√©todos"
    )
    
    test_all_methods_with_same_text(
        "Estoy muy decepcionado con la calidad del servicio",
        "Texto negativo para comparar m√©todos"
    )
    
    # Prueba de validaci√≥n en lote
    test_batch_validation()
    
    print("\nüéâ Todas las pruebas completadas!")

def test_performance_comparison():
    """Prueba de rendimiento comparando m√©todos"""
    print("\n‚ö° Prueba de rendimiento comparando m√©todos...")
    
    test_text = "Este es un texto de prueba para medir el rendimiento de diferentes m√©todos de an√°lisis de sentimientos."
    
    methods = ["transformers", "textblob", "vader"]
    performance_results = {}
    
    for method in methods:
        print(f"\n   üîç Probando m√©todo: {method}")
        times = []
        
        # Ejecutar 5 veces para obtener promedio
        for i in range(5):
            try:
                start_time = time.time()
                response = requests.post(
                    f"{API_BASE_URL}/validate",
                    json={"text": test_text, "language": "es", "sentiment_method": method}
                )
                end_time = time.time()
                
                if response.status_code == 200:
                    processing_time = response.json().get('processing_time', end_time - start_time)
                    times.append(processing_time)
                    print(f"     Ejecuci√≥n {i+1}: {processing_time:.3f}s")
                else:
                    print(f"     ‚ùå Error en ejecuci√≥n {i+1}")
                    
            except Exception as e:
                print(f"     ‚ùå Error en ejecuci√≥n {i+1}: {e}")
        
        if times:
            avg_time = sum(times) / len(times)
            performance_results[method] = avg_time
            print(f"     ‚è±Ô∏è  Tiempo promedio: {avg_time:.3f}s")
    
    # Mostrar resumen de rendimiento
    print(f"\nüìä Resumen de rendimiento:")
    sorted_methods = sorted(performance_results.items(), key=lambda x: x[1])
    for i, (method, time) in enumerate(sorted_methods):
        medal = "ü•á" if i == 0 else "ü•à" if i == 1 else "ü•â"
        print(f"   {medal} {method}: {time:.3f}s promedio")

if __name__ == "__main__":
    print("=" * 70)
    print("üß™ TESTER DE API DE VALIDACI√ìN DE TEXTOS v2.0")
    print("üöÄ Integra: Transformers (BERT), TextBlob y VADER")
    print("=" * 70)
    
    try:
        run_all_tests()
        test_performance_comparison()
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Pruebas interrumpidas por el usuario")
    except Exception as e:
        print(f"\nüí• Error general: {e}")
    
    print("\n" + "=" * 70)
    print("üèÅ Fin de las pruebas")
    print("=" * 70) 